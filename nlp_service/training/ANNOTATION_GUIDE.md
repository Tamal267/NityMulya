# Dataset Annotation Guide

## For AI-Enhanced Complaint Management System

This guide helps you create a labeled dataset for training BanglaBERT models.

---

## **Dataset Structure**

Create CSV files with the following columns:

### **1. Priority Classification Dataset**

**File:** `labeled_complaints_priority.csv`

| complaint_text                           | priority_label | language |
| ---------------------------------------- | -------------- | -------- |
| ‡¶Ü‡¶Æ‡¶æ‡¶∞ ‡¶¨‡¶æ‡¶ö‡ßç‡¶ö‡¶æ ‡¶è‡¶á ‡¶ñ‡¶æ‡¶¨‡¶æ‡¶∞ ‡¶ñ‡ßá‡¶Ø‡¶º‡ßá ‡¶Ö‡¶∏‡ßÅ‡¶∏‡ßç‡¶• ‡¶π‡¶Ø‡¶º‡ßá‡¶õ‡ßá | Urgent         | bn       |
| ‡¶¶‡ßã‡¶ï‡¶æ‡¶®‡ßá ‡¶Æ‡ßá‡¶Ø‡¶º‡¶æ‡¶¶‡ßã‡¶§‡ßç‡¶§‡ßÄ‡¶∞‡ßç‡¶£ ‡¶™‡¶£‡ßç‡¶Ø ‡¶¨‡¶ø‡¶ï‡ßç‡¶∞‡¶ø ‡¶ï‡¶∞‡¶õ‡ßá   | High           | bn       |
| ‡¶¶‡¶æ‡¶Æ ‡¶è‡¶ï‡¶ü‡ßÅ ‡¶¨‡ßá‡¶∂‡¶ø ‡¶®‡¶ø‡¶Ø‡¶º‡ßá‡¶õ‡ßá                    | Medium         | bn       |
| ‡¶™‡¶£‡ßç‡¶Ø ‡¶∏‡¶Æ‡ßç‡¶™‡¶∞‡ßç‡¶ï‡ßá ‡¶ú‡¶æ‡¶®‡¶§‡ßá ‡¶ö‡¶æ‡¶á                  | Low            | bn       |

### **2. Validity Detection Dataset**

**File:** `labeled_complaints_validity.csv`

| complaint_text                | is_valid | reason               |
| ----------------------------- | -------- | -------------------- |
| ‡¶¶‡ßã‡¶ï‡¶æ‡¶®‡ßá ‡¶™‡¶ö‡¶æ ‡¶Æ‡¶æ‡¶õ ‡¶¨‡¶ø‡¶ï‡ßç‡¶∞‡¶ø ‡¶ï‡¶∞‡¶õ‡ßá    | true     | legitimate_complaint |
| FREE PRIZE WIN NOW CLICK HERE | false    | spam                 |
| ‡¶≠‡¶æ‡¶≤‡ßã                          | false    | too_short            |
| ‡¶¶‡ßã‡¶ï‡¶æ‡¶®‡¶¶‡¶æ‡¶∞ ‡¶ì‡¶ú‡¶®‡ßá ‡¶ï‡¶Æ ‡¶¶‡¶ø‡¶Ø‡¶º‡ßá‡¶õ‡ßá      | true     | legitimate_complaint |

### **3. Sentiment Analysis Dataset**

**File:** `labeled_complaints_sentiment.csv`

| complaint_text                   | sentiment | emotion_intensity |
| -------------------------------- | --------- | ----------------- |
| ‡¶è‡¶á ‡¶¶‡ßã‡¶ï‡¶æ‡¶®‡ßá‡¶∞ ‡¶∏‡ßá‡¶¨‡¶æ ‡¶Ö‡¶§‡ßç‡¶Ø‡¶®‡ßç‡¶§ ‡¶ñ‡¶æ‡¶∞‡¶æ‡¶™!!! | Negative  | high              |
| ‡¶¶‡¶æ‡¶Æ ‡¶è‡¶ï‡¶ü‡ßÅ ‡¶¨‡ßá‡¶∂‡¶ø ‡¶ï‡¶ø‡¶®‡ßç‡¶§‡ßÅ ‡¶Æ‡¶æ‡¶® ‡¶≠‡¶æ‡¶≤‡ßã    | Neutral   | medium            |
| ‡¶™‡¶£‡ßç‡¶Ø‡ßá‡¶∞ ‡¶ó‡ßÅ‡¶£‡¶ó‡¶§ ‡¶Æ‡¶æ‡¶® ‡¶®‡¶ø‡¶Ø‡¶º‡ßá ‡¶∏‡¶Æ‡¶∏‡ßç‡¶Ø‡¶æ    | Negative  | medium            |

---

## **Annotation Guidelines**

### **Priority Classification**

#### **Urgent**

Requires immediate action within 24 hours.

**Examples:**

- ‚úÖ Health hazards: "‡¶∏‡ßç‡¶¨‡¶æ‡¶∏‡ßç‡¶•‡ßç‡¶Ø ‡¶∏‡¶Æ‡¶∏‡ßç‡¶Ø‡¶æ ‡¶π‡¶Ø‡¶º‡ßá‡¶õ‡ßá", "‡¶¨‡¶ø‡¶∑‡¶ï‡ßç‡¶∞‡¶ø‡¶Ø‡¶º‡¶æ"
- ‚úÖ Child safety: "‡¶¨‡¶æ‡¶ö‡ßç‡¶ö‡¶æ‡¶∞ ‡¶ï‡ßç‡¶∑‡¶§‡¶ø ‡¶π‡¶Ø‡¶º‡ßá‡¶õ‡ßá"
- ‚úÖ Severe fraud: "‡¶™‡ßç‡¶∞‡¶ö‡ßÅ‡¶∞ ‡¶ü‡¶æ‡¶ï‡¶æ ‡¶π‡¶æ‡¶∞‡¶ø‡¶Ø‡¶º‡ßá‡¶õ‡¶ø"
- ‚úÖ Expired/poisonous products: "‡¶Æ‡ßá‡¶Ø‡¶º‡¶æ‡¶¶‡ßã‡¶§‡ßç‡¶§‡ßÄ‡¶∞‡ßç‡¶£ ‡¶ñ‡¶æ‡¶¨‡¶æ‡¶∞"

**Keywords:** ‡¶ú‡¶∞‡ßÅ‡¶∞‡¶ø, urgent, ‡¶∏‡ßç‡¶¨‡¶æ‡¶∏‡ßç‡¶•‡ßç‡¶Ø, health, ‡¶∂‡¶ø‡¶∂‡ßÅ, child

#### **High**

Serious issues requiring action within 3-7 days.

**Examples:**

- ‚úÖ Quality problems: "‡¶™‡¶£‡ßç‡¶Ø ‡¶®‡¶∑‡ßç‡¶ü", "‡¶ñ‡¶æ‡¶∞‡¶æ‡¶™ ‡¶Æ‡¶æ‡¶®"
- ‚úÖ Fraud: "‡¶™‡ßç‡¶∞‡¶§‡¶æ‡¶∞‡¶£‡¶æ ‡¶ï‡¶∞‡ßá‡¶õ‡ßá", "‡¶†‡¶ï‡¶ø‡¶Ø‡¶º‡ßá‡¶õ‡ßá"
- ‚úÖ Expired products (no health issue yet)
- ‚úÖ Significant overcharging

**Keywords:** ‡¶ñ‡¶æ‡¶∞‡¶æ‡¶™, bad, ‡¶®‡¶∑‡ßç‡¶ü, damaged, ‡¶™‡ßç‡¶∞‡¶§‡¶æ‡¶∞‡¶£‡¶æ, fraud

#### **Medium**

Standard complaints, action within 2 weeks.

**Examples:**

- ‚úÖ Price issues: "‡¶¶‡¶æ‡¶Æ ‡¶¨‡ßá‡¶∂‡¶ø", "overpriced"
- ‚úÖ Weight shortage: "‡¶ì‡¶ú‡¶® ‡¶ï‡¶Æ"
- ‚úÖ Service quality: "‡¶¨‡ßç‡¶Ø‡¶¨‡¶π‡¶æ‡¶∞ ‡¶ñ‡¶æ‡¶∞‡¶æ‡¶™"
- ‚úÖ Packaging issues

**Keywords:** ‡¶¶‡¶æ‡¶Æ, price, ‡¶ì‡¶ú‡¶®, weight, ‡¶™‡¶∞‡¶ø‡¶Æ‡¶æ‡¶£, quantity

#### **Low**

Minor issues or inquiries.

**Examples:**

- ‚úÖ General questions: "‡¶ú‡¶æ‡¶®‡¶§‡ßá ‡¶ö‡¶æ‡¶á"
- ‚úÖ Minor inconveniences
- ‚úÖ Feedback (not really complaints)

---

### **Validity Detection**

#### **Valid Complaints**

Real complaints about products/services.

**Criteria:**

- ‚úÖ Mentions shop, product, or service
- ‚úÖ Describes specific problem
- ‚úÖ Reasonable length (>5 words)
- ‚úÖ Contains context

**Examples:**

- "‡¶¶‡ßã‡¶ï‡¶æ‡¶®‡ßá ‡¶™‡¶ö‡¶æ ‡¶∏‡¶¨‡¶ú‡¶ø ‡¶¨‡¶ø‡¶ï‡ßç‡¶∞‡¶ø ‡¶ï‡¶∞‡¶õ‡ßá"
- "‡¶ì‡¶ú‡¶®‡ßá ‡¶ï‡¶Æ ‡¶¶‡¶ø‡¶Ø‡¶º‡ßá‡¶õ‡ßá"
- "I bought expired biscuit"

#### **Invalid/Spam**

**Criteria:**

- ‚ùå Contains spam keywords (lottery, prize, free)
- ‚ùå Too short (<5 words): "‡¶ñ‡¶æ‡¶∞‡¶æ‡¶™", "bad"
- ‚ùå No context or details
- ‚ùå Promotional content
- ‚ùå Random text

**Examples:**

- "WIN FREE PRIZE"
- "‡¶ñ‡¶æ‡¶∞‡¶æ‡¶™" (just one word)
- "‡¶ï‡ßç‡¶≤‡¶ø‡¶ï ‡¶ï‡¶∞‡ßÅ‡¶® ‡¶Ö‡¶´‡¶æ‡¶∞ ‡¶™‡¶æ‡¶®"

---

### **Sentiment Analysis**

#### **Negative**

Expresses dissatisfaction, anger, or frustration.

**Examples:**

- "‡¶ñ‡ßÅ‡¶¨‡¶á ‡¶ñ‡¶æ‡¶∞‡¶æ‡¶™ ‡¶Ö‡¶≠‡¶ø‡¶ú‡ßç‡¶û‡¶§‡¶æ!!!"
- "‡¶∞‡¶æ‡¶ó‡ßá ‡¶Ö‡¶∏‡ßç‡¶•‡¶ø‡¶∞"
- "‡¶≠‡¶Ø‡¶º‡¶æ‡¶®‡¶ï ‡¶∏‡ßá‡¶¨‡¶æ"

**Keywords:** ‡¶ñ‡¶æ‡¶∞‡¶æ‡¶™, bad, ‡¶∞‡¶æ‡¶ó, angry, ‡¶≠‡¶Ø‡¶º‡¶æ‡¶®‡¶ï, terrible

#### **Neutral**

Factual complaint without strong emotion.

**Examples:**

- "‡¶¶‡¶æ‡¶Æ ‡¶è‡¶ï‡¶ü‡ßÅ ‡¶¨‡ßá‡¶∂‡¶ø ‡¶õ‡¶ø‡¶≤"
- "‡¶™‡¶£‡ßç‡¶Ø‡ßá‡¶∞ ‡¶ì‡¶ú‡¶® ‡¶†‡¶ø‡¶ï ‡¶õ‡¶ø‡¶≤ ‡¶®‡¶æ"

#### **Positive**

Rare in complaints, but possible in mixed feedback.

**Examples:**

- "‡¶™‡¶£‡ßç‡¶Ø ‡¶≠‡¶æ‡¶≤‡ßã ‡¶ï‡¶ø‡¶®‡ßç‡¶§‡ßÅ ‡¶¶‡¶æ‡¶Æ ‡¶¨‡ßá‡¶∂‡¶ø"
- "‡¶¶‡ßã‡¶ï‡¶æ‡¶®‡¶¶‡¶æ‡¶∞ ‡¶≠‡¶¶‡ßç‡¶∞ ‡¶ï‡¶ø‡¶®‡ßç‡¶§‡ßÅ ‡¶∏‡ßá‡¶¨‡¶æ ‡¶ß‡ßÄ‡¶∞"

---

## **Data Collection Strategy**

### **Option 1: Manual Collection**

1. **From existing complaints** in your system
2. **Create synthetic complaints** based on common patterns
3. **Crowdsource** from friends/colleagues

### **Option 2: Real User Data**

1. Deploy system without AI initially
2. Collect real complaints
3. Manually annotate 500-1000 samples
4. Train model
5. Deploy AI system

---

## **Sample Size Requirements**

### **Minimum (for thesis validation)**

- Priority: 500 labeled complaints (125 per class)
- Validity: 300 labeled (150 valid, 150 invalid)
- Sentiment: 300 labeled (100 per class)

### **Recommended (for production)**

- Priority: 2000+ labeled complaints
- Validity: 1000+ labeled
- Sentiment: 1000+ labeled

---

## **Inter-Annotator Agreement**

For research validity, have 2-3 annotators label the same 100 samples.

**Calculate Cohen's Kappa:**

```python
from sklearn.metrics import cohen_kappa_score

annotator1 = [1, 2, 3, 1, 2, ...]
annotator2 = [1, 2, 2, 1, 2, ...]

kappa = cohen_kappa_score(annotator1, annotator2)
print(f"Agreement: {kappa}")
# Kappa > 0.7 is good
```

---

## **Data Augmentation**

Increase dataset size using augmentation:

### **1. Back-translation**

Bengali ‚Üí English ‚Üí Bengali

```python
from googletrans import Translator

translator = Translator()

# Original
text = "‡¶¶‡ßã‡¶ï‡¶æ‡¶®‡ßá ‡¶™‡¶ö‡¶æ ‡¶Æ‡¶æ‡¶õ ‡¶¨‡¶ø‡¶ï‡ßç‡¶∞‡¶ø ‡¶ï‡¶∞‡¶õ‡ßá"

# Bengali ‚Üí English
english = translator.translate(text, src='bn', dest='en').text

# English ‚Üí Bengali
augmented = translator.translate(english, src='en', dest='bn').text
```

### **2. Synonym Replacement**

Replace words with Bengali synonyms:

- ‡¶¶‡¶æ‡¶Æ ‚Üí ‡¶Æ‡ßÇ‡¶≤‡ßç‡¶Ø
- ‡¶ñ‡¶æ‡¶∞‡¶æ‡¶™ ‚Üí ‡¶®‡¶ø‡¶Æ‡ßç‡¶®‡¶Æ‡¶æ‡¶®‡ßá‡¶∞
- ‡¶¶‡ßã‡¶ï‡¶æ‡¶® ‚Üí ‡¶¨‡ßç‡¶Ø‡¶¨‡¶∏‡¶æ ‡¶™‡ßç‡¶∞‡¶§‡¶ø‡¶∑‡ßç‡¶†‡¶æ‡¶®

### **3. Code-mixing (Banglish)**

Create Banglish versions:

- "‡¶¶‡ßã‡¶ï‡¶æ‡¶®‡ßá ‡¶™‡¶ö‡¶æ ‡¶Æ‡¶æ‡¶õ ‡¶¨‡¶ø‡¶ï‡ßç‡¶∞‡¶ø ‡¶ï‡¶∞‡¶õ‡ßá" ‚Üí "dokane pocha mach bikri korche"

---

## **Annotation Tools**

### **Option 1: Google Sheets**

Simple and collaborative.

### **Option 2: Label Studio**

Open-source annotation tool.

```bash
pip install label-studio
label-studio start
```

### **Option 3: Custom Web App**

Build simple annotation interface with React/Flutter.

---

## **Quality Checks**

Before training:

1. ‚úÖ **Check class balance**

   ```python
   df['priority_label'].value_counts()
   ```

2. ‚úÖ **Remove duplicates**

   ```python
   df.drop_duplicates(subset=['complaint_text'])
   ```

3. ‚úÖ **Check for mislabeled data**

   - Read 10% randomly
   - Fix obvious errors

4. ‚úÖ **Language distribution**
   ```python
   df['language'].value_counts()
   ```

---

## **Example Annotation Session**

```python
import pandas as pd

# Load existing complaints
complaints = [
    "‡¶¶‡ßã‡¶ï‡¶æ‡¶®‡ßá ‡¶Æ‡ßá‡¶Ø‡¶º‡¶æ‡¶¶‡ßã‡¶§‡ßç‡¶§‡ßÄ‡¶∞‡ßç‡¶£ ‡¶¨‡¶ø‡¶∏‡ßç‡¶ï‡ßÅ‡¶ü ‡¶¨‡¶ø‡¶ï‡ßç‡¶∞‡¶ø ‡¶ï‡¶∞‡¶õ‡ßá",
    "‡¶¶‡¶æ‡¶Æ ‡¶è‡¶ï‡¶ü‡ßÅ ‡¶¨‡ßá‡¶∂‡¶ø ‡¶®‡¶ø‡¶Ø‡¶º‡ßá‡¶õ‡ßá",
    "‡¶¨‡¶æ‡¶ö‡ßç‡¶ö‡¶æ ‡¶ñ‡ßá‡¶Ø‡¶º‡ßá ‡¶Ö‡¶∏‡ßÅ‡¶∏‡ßç‡¶• ‡¶π‡¶Ø‡¶º‡ßá‡¶õ‡ßá",
    # ... more complaints
]

# Annotate
data = []
for text in complaints:
    print(f"\nComplaint: {text}")

    # Priority
    priority = input("Priority (Low/Medium/High/Urgent): ")

    # Validity
    is_valid = input("Valid? (yes/no): ") == "yes"

    # Sentiment
    sentiment = input("Sentiment (Positive/Neutral/Negative): ")

    data.append({
        'complaint_text': text,
        'priority_label': priority,
        'is_valid': is_valid,
        'sentiment': sentiment,
        'language': 'bn'
    })

# Save
df = pd.DataFrame(data)
df.to_csv('labeled_complaints.csv', index=False)
print(f"\n‚úÖ Saved {len(df)} labeled complaints")
```

---

## **Next Steps After Annotation**

1. ‚úÖ Create labeled CSV files
2. ‚úÖ Run quality checks
3. ‚úÖ Train models using `train_priority_classifier.py`
4. ‚úÖ Evaluate on test set
5. ‚úÖ Deploy fine-tuned models
6. ‚úÖ Document results in thesis

---

## **Resources**

- **BanglaBERT Paper:** https://arxiv.org/abs/2101.00204
- **Hugging Face Datasets:** https://huggingface.co/docs/datasets
- **Label Studio:** https://labelstud.io/
- **Bengali NLP Resources:** https://github.com/sagorbrur/bnlp

---

**Good luck with your thesis! üéì**
